{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabelas de espalhamento (tabelas hash)\n",
    "\n",
    "Uma tabela hash permite a implementação da operação de busca com um número de operações esperado que\n",
    "não depende do tamanho da tabela, $O(1)$. Embora o custo de pior caso ainda seja proporcional ao\n",
    "tamanho da tabela, $O(n)$. Em geral, uma tabela hash possui dois componentes principais: um vetor de\n",
    "<i>buckets</i> e uma função <i>hash</i> (função de espalhamento).\n",
    "\n",
    "## Vetor de <i>buckets</i>\n",
    "O vetor de <i>buckets</i> de uma tabela <i>hash</i> é um vetor $A$ de tamanho $N$ em que cada célula de $A$\n",
    "é uma coleção (<i>bucket</i>) de pares chave-valor. O inteiro $N$ define o número de <i>buckets</i>\n",
    "do vetor. \n",
    "\n",
    "Caso as chaves fossem inteiros bem distribuídos no intervalo $[0, N-1]$, então o vetor de <i>buckets</i>\n",
    "seria suficiente para a tabela <i>hash</i>. Nesse caso, uma entrada $e$ com chave $k$ seria inserida no <i>bucket</i>\n",
    "$A[k]$. Caso as chaves sejam inteiros únicos no intervalo $[0, N-1]$, então, cada <i>bucket</i> armazena\n",
    "no máximo uma entrada. Então, buscas, inserções e remoções no vetor de <i>buckets</i> são $O(1)$. No\n",
    "entanto, há duas desvantagens:\n",
    "\n",
    "- Se $N$ for muito maior do que o número de entradas, então há um grande desperdício de memória.\n",
    "- As chaves devem ser necessariamente inteiras, o que nem sempre é viável. \n",
    "\n",
    "Devido a essas duas desvantagens, o vetor de <i>buckets</i> é utilizado em conjunto com alguma função de\n",
    "espalhamento.\n",
    "\n",
    "## Função de espalhamento (função <i>hash</i>)\n",
    "    \n",
    "Uma função hash $h$ mapeia cada chave $k$ em um inteiro no intervalo $[0, N-1]$, em que $N$ é o\n",
    "tamanho do vetor de <i>buckets</i>. Com isso, é possível aplicar a função <i>hash</i> para chaves arbitrárias,\n",
    "não necessariamente inteiras. Assim, uma entrada com chave $k$ é armazenada no <i>bucket</i> $A[h(k)]$. \n",
    "\n",
    "Caso haja duas entradas com chaves $k_{1}$ e $k_{2}$ tal que $h(k_{1}) = h(k_{2})$, então tais\n",
    "entradas estão mapeadas para o mesmo <i>bucket</i> e diz-se que ocorreu uma colisão. Se o <i>bucket</i> em questão\n",
    "não conseguir armazenar mais de um elemento, então não é possível armazenar ambos os elementos\n",
    "na mesma tabela hash. Há maneiras de lidar com a colisão, mas a primeira estratégia é evitá-las. \n",
    "\n",
    "Uma \"boa\" função <i>hash</i>:\n",
    "- Mapeia as chaves do mapa de forma a minimizar as colisões.\n",
    "- É fácil (rápida) de computar. \n",
    "\n",
    "A avaliação de uma função hash é vista como duas ações: \n",
    "\n",
    "1) Mapeamento da chave $k$ em um inteiro (código hash ou <i>hash code</i>).\n",
    "\n",
    "2) Mapeamento do inteiro em um dos índices, $[0, N-1]$, do vetor de <i>buckets</i> (função de\n",
    "   compressão).\n",
    "\n",
    "### Código <i>hash</i>\n",
    "\n",
    "Essa primeira ação consiste em mapear uma chave arbitrária $k$ em um valor inteiro. Esse inteiro não\n",
    "precisa estar no intervalo $[0, N-1]$ e pode, inclusive, ser negativo. \n",
    "\n",
    "Os códigos <i>hash</i> descritos a seguir são baseados na hipótese de que o número de <i>bits</i> de cada tipo é\n",
    "conhecido.\n",
    "\n",
    "#### Convertendo para um inteiro\n",
    "\n",
    "Caso o tipo de dado seja representado usando no máximo o mesmo número de <i>bits</i> da representação de\n",
    "inteiros dos códigos <i>hash</i>, então, é possível simplesmente utilizar a representação inteira dos\n",
    "<i>bits</i> como código para o dado. \n",
    "\n",
    "Para tipos maiores, em que a representação utiliza o dobro de\n",
    "<i>bits</i> de um <i>inteiro</i>, por exemplo, uma possibilidade é rebaixar o valor para <i>int</i>. No entanto, nesse caso, metade\n",
    "da informação é perdida, o que pode aumentar consideravelmente o número de colisões. Um melhoria\n",
    "consiste em somar as representações inteiras dos <i>bits</i> mais significativos com a dos bits menos\n",
    "significativos. \n",
    "\n",
    "De fato, a abordagem de somar as componentes pode ser estendida para objetos cuja a representação\n",
    "binária pode ser vista como uma tupla $x = (x_{0}, x_{1}, \\ldots, x_{m-1})$. Assim, o código <i>hash</i>\n",
    "de $x$ pode ser definido como $\\displaystyle \\sum_{i=0}^{m-1}x_{i}$. \n",
    "\n",
    "#### Códigos hash polinomiais\n",
    "\n",
    "O código apresentado anteriormente não é adequado para strings e outros objetos em que a ordem dos\n",
    "elementos da tupla $(x_{0}, x_{1}, \\ldots, x_{k-1})$ é significativa. Por exemplo, no caso das\n",
    "strings <i>temp01</i> e <i>temp10</i> haveria colisão, também haveria colisão nas strings <i>stop</i>, <i>tops</i>,\n",
    "<i>pots</i> e <i>spot</i>. Uma alternativa, que considera a ordem dos elementos $x_{i}$ consiste em escolher\n",
    "uma constante não nula $a \\neq 1$ e utilizar\n",
    "\n",
    "$$\n",
    "x_{0}a^{k-1} + x_{1}{a}^{k-2} + \\ldots + x_{k-2}a + x_{k-1}\n",
    "$$\n",
    "\n",
    "como valor do código <i>hash</i>.\n",
    "\n",
    "Alguns estudos sugerem que 33, 37, 39 e 41 são boas escolhas para $a$ quando trabalhando com strings\n",
    "de palavras em inglês. Uma lista com 50000 palavras produziu menos de 7 colisões em cada um dos\n",
    "casos. \n",
    "\n",
    "#### Códigos hash com deslocamento cíclico\n",
    "\n",
    "Uma variação dos códigos polinomiais consiste em substituir a multiplicação por um deslocamento\n",
    "(<i>shift</i>) cíclico de um determinado número de <i>bits</i>. Por exemplo, assumindo uma palavra de 32-bits de\n",
    "comprimento, um <i>shift</i> cíclico de 5 <i>bits</i> pode ser obtido com uma operação lógica <i>ou</i> <i>bit</i> a <i>bit</i>\n",
    "entre um <i>shift</i> para a esquerda de 5 bits e um a direita de 27 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3890768, 3918451, 3886676)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hash_code(s):\n",
    "    mask = (1 << 32) - 1\n",
    "    h=0\n",
    "    for character in s:\n",
    "        h = (h << 5 & mask) | (h >> 27)\n",
    "        h += ord(character)\n",
    "    return h\n",
    "\n",
    "hash_code(\"stop\"), hash_code(\"tops\"), hash_code(\"spot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Códigos <i>hash</i> em Python\n",
    "\n",
    "O mecanismo padrão para computar códigos <i>hash</i> em Python é uma função embutida com assinatura <i>hash(x)</i> que retorna um inteiro, a ser utilizado como código <i>hash</i>. No entanto, apenas tipos imutáveis podem ser \"hasheados\" em Python. Isso mantém o código <i>hash</i> do objeto inalterado durante seu ciclo de vida. Dentre os tipos imutáveis estão <i>int</i>, <i>float</i>, <i>str</i> e <i>tuplas</i>\n",
    "\n",
    "Instâncias de classes definidas pelo usuário são consideradas não \"hasheáveis\" por padrão. No entanto, uma função que computa o código <i>hash</i> pode ser definida. O código retornado deve refletir a imutabilidade dos atributos da instância da classe. É comum retornar um código <i>hash</i> baseado nos códigos <i>hash</i> dos atributos imutáveis da instância.\n",
    "\n",
    "É importante que caso a classe defina equivalência entre os objetos através do método <i>\\__eq\\__</i>, então, os códigos <i>hash</i> deve refletir tal equivalência, isto é, se $x == y$, então $hash(x) == hash(y)$.\n",
    "\n",
    "\n",
    "### Funções de compressão\n",
    "\n",
    "Em geral, o código <i>hash</i> não é imediatamente útil como índice do vetor de <i>buckets</i> devido à\n",
    "possibilidade de seu valor extrapolar os limites do vetor (para mais ou para menos). Portanto, é\n",
    "necessário um passo adicional para garantir o mapeamento do código no intervalo $[0, N-1]$.\n",
    "\n",
    "#### O método da divisão\n",
    "\n",
    "Uma conversão simples é utilizar:\n",
    "$$\n",
    "h(k) = |k| mod N.\n",
    "$$\n",
    "\n",
    "A escolha de $N$ pode impactar na colisão. Idealmente, deseja-se que a probabilidade de duas chaves\n",
    "serem mapeadas para o mesmo <i>bucket</i> seja $\\frac{1}{N}$. Na prática, sugere-se escolher $N$ primo\n",
    "para reduzir a chance de aparecem padrões que aumentam as colisões. Embora, isso não seja\n",
    "garantidamente a melhor escolha pois podem haver padrões nos dados que prejudiquem tal escolha.\n",
    "\n",
    "#### O método MSD (<i>MAD -- Multiply, add and divide</i>)\n",
    "\n",
    "Um método mais sofisticado que ajuda a eliminar padrões repetidos nas chaves é o método MAD.\n",
    "\n",
    "$$\n",
    "h(k) = |ak + b| mod N.\n",
    "$$\n",
    "\n",
    "onde $N$ é escolhido como número primo e $a$ e $b$ são inteiros não negativos aleatoriamente\n",
    "escolhidos no momento de criação da função de forma que $a mod N \\neq 0$. \n",
    "\n",
    "\n",
    "## Gerenciamento de colisões\n",
    "\n",
    "Embora haja um esforço para minimizar o número de colisões,\n",
    "mecanismos para gerenciar a tabela <i>hash</i> quando elas ocorrem ainda são necessários. Particularmente,\n",
    "as colisões dificultam as operações de busca, inserção (ou modificação) e remoção.\n",
    "\n",
    "### Separate Chaining\n",
    "\n",
    "Uma maneira simples e efetiva de lidar com colisões é ter cada /bucket/ $A[i]$ armazenando um\n",
    "pequeno mapa $M_{i}$ implementado utilizando uma lista. Esse mapa armazena as entradas $(k, v)$ tais\n",
    "que $h(k) = i$. \n",
    "\n",
    "Nesse caso, a abordagem de <i>separate chaining</i> delega para o mini-mapa do <i>bucket</i> correspondente a\n",
    "realização da operação fundamental. \n",
    "\n",
    "Essa implementação simples é suficiente quando o tamanho das listas $M_{i}$ é pequeno. \n",
    "\n",
    "Assumindo que, em uma boa função hash, a probabilidade de uma chave ser mapeada para um <i>bucket</i>\n",
    "qualquer é aproximadamente $\\frac{1}{N}$, sendo $N$ o tamanho do vetor de <i>buckets</i>. Então, caso\n",
    "haja $n$ entradas para seram adicionadas, cada <i>bucket</i> ficaria com o  $\\lambda = \\frac{n}{N}$ elementos. Esse\n",
    "valor é conhecido como fator de carga da tabela <i>hash</i>. No pior caso, as funções de inserção, busca e remoção podem ser implementadas em $O(\\lceil \\frac{n}{N} \\rceil)$. Embora, o tempo esperado seja\n",
    "$O(1)$ se $n$ for $O(N)$.\n",
    "\n",
    "Apesar de sua simplicidade, o <i>separate chaining</i> possui a desvantagem de necessitar de uma estrutura\n",
    "de dados auxiliar (lista) para armazenar as entradas com as chaves que colidiram. \n",
    "\n",
    "### <i>Open addressing</i> (endereçamento aberto)\n",
    "\n",
    "A estratégia de <i>open addressing</i> economiza espaço por não utilizar estruturas adicionais, embora seja\n",
    "mais complexa. Ainda, essa estratégia requer que o fator de carga seja no máximo 1 e que as entradas\n",
    "sejam armazenadas diretamente nas células do vetor de <i>buckets</i>. Há diversas variações dessa\n",
    "estratégia.\n",
    "\n",
    "#### <i>Probing</i> (sondagem) linear e variantes\n",
    "\n",
    "Talvez a técnica mais simples de <i>probing linear</i>.  Nesse método, tenta-se inserir a entrada $(k, v)$\n",
    "no <i>bucket</i> $A[i]$, caso o <i>bucket</i> esteja ocupado, então tenta-se inserir no <i>bucket</i> seguinte, de\n",
    "maneira circular, até que seja possível inserir a entrada.\n",
    "\n",
    "Note que, com essa estratégia, a busca por uma determinada chave precisa prosseguir até que seja\n",
    "encontrada uma célula vazia. \n",
    "\n",
    "A operação <i>erase(k)</i> pode ser implementada marcando a célula removida com um caractere especial\n",
    "indicando a disponibilidade da posição. \n",
    "\n",
    "A operação inserção deve se lembrar de posições disponíveis na busca por $k$, para que seja\n",
    "realizada a inserção caso $k$ não seja encontrado. \n",
    "\n",
    "Dessa forma, o <i>probing linear</i> economiza espaço mas complica as operações elementares. Ainda, a\n",
    "desvantagem de poluir faixas contínuas do vetor de <i>buckets</i>. Tais porçoes contínuas fazem com que as\n",
    "buscas sejam mais custosas.\n",
    "\n",
    "Variantes dessa estratégia consideram uma busca não linear, isto é, ao invés de verificar a posição\n",
    "seguinte do vetor <i>bucket</i>, a posição a ser verificada é baseada em uma função da posição\n",
    "atual. Duas opções conhecidas são utilizar uma função quadrática ou uma segunda função <i>hash</i>. \n",
    "\n",
    "O probing linear e suas variações são interessantes quando a memória é limitada, caso isso não seja\n",
    "um problema, o <i>separate chaining</i> costuma ser mais indicado.\n",
    "\n",
    "\n",
    "### Fator de carga e rehashing\n",
    "\n",
    "Em geral, o fator de carga $\\lambda = \\frac{n}{N}$ deve ser mantido menor do que a\n",
    "unidade. Experimentos sugerem que para a estratégia de <i>open addressing</i> deve-se manter $\\lambda <\n",
    "0.5$ e no caso de <i>separate chaining</i> $\\lambda < 0.9$. \n",
    "\n",
    "No caso de um fator de carga alto, uma estratégia utilizada consiste em reinserir os elementos em\n",
    "uma tabela <i>hash</i> maior (pelo menos o dobro do tamanho).\n",
    "\n",
    "# Implementação de um dicionário com tabela <i>hash</i>\n",
    "\n",
    "A implementação do dicionário considera a classe MapBase, definida anteriormente. É definida a classe \"abstrata\" <i>HashMapBase</i>, responsável por gerenciar o vetor de <i>buckets</i>. Assume-se que o código <i>hash</i> do objeto a ser usado como chave está definido e, então, utiliza-se a estratégia <i>multiply-add-divide</i> para mapeá-la dentro dos limites da lista de <i>buckets</i>. Note que as lógicas de busca, inserção e remoção dependem da implementação, apenas as lógicas mais gerais, referentes ao vetor de <i>buckets</i> são definidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashMapBase(MapBase):\n",
    "    \"\"\"Abstract base class for map using hash-table with MAD compression.\n",
    "    Keys must be hashable and non-None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cap=11, p=109345121):\n",
    "        \"\"\"Create an empty hash-table map.\n",
    "        cap     initial table size (default 11)\n",
    "        p       positive prime used for MAD (default 109345121)\n",
    "        \"\"\"\n",
    "        self._table = cap * [None]\n",
    "        self._n = 0                                   # number of entries in the map\n",
    "        self._prime = p                               # prime for MAD compression\n",
    "        self._scale = 1 + randrange(p-1)              # scale from 1 to p-1 for MAD\n",
    "        self._shift = randrange(p)\n",
    "    \n",
    "    def _hash_function(self, k):\n",
    "        return (hash(k)*self._scale + self._shift) % self._prime % len(self._table)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._n\n",
    "    \n",
    "    def _resize(self, c):\n",
    "        \"\"\"Resize bucket array to capacity c and rehash all items.\"\"\"\n",
    "        old = list(self.items())       # use iteration to record existing items\n",
    "        self._table = c * [None]       # then reset table to desired capacity\n",
    "        self._n = 0                    # n recomputed during subsequent adds\n",
    "        for (k,v) in old:\n",
    "            self[k] = v                  # reinsert old key-value pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O gerenciamento das colisões é feito pela classe que implementa a classe abstrata, em particular os métodos <i>bucket\\_getitem</i>, <i>bucket\\_setitem</i> e <i>_bucket_delitem</i>.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getitem__(self, k):\n",
    "    j = self._hash_function(k)\n",
    "    return self._bucket_getitem(j, k)             # may raise KeyError\n",
    "\n",
    "def __setitem__(self, k, v):\n",
    "    j = self._hash_function(k)\n",
    "    self._bucket_setitem(j, k, v)                 # subroutine maintains self._n\n",
    "    if self._n > len(self._table) // 2:           # keep load factor <= 0.5\n",
    "        self._resize(2 * len(self._table) - 1)      # number 2^x - 1 is often prime\n",
    "\n",
    "def __delitem__(self, k):\n",
    "    j = self._hash_function(k)\n",
    "    self._bucket_delitem(j, k)                    # may raise KeyError\n",
    "    self._n -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta implementação, foi utilizada a estratégia <i>separate chaining</i> para lidar com as colisões, implementada na classe <i>ChainHashMap</i>. Então, é a classe <i>ChainHashMap</i>, filha da <i>HashMapBase</i> que implementa os métodos <i>_bucket_getitem</i>, <i>_bucket_setitem</i> e <i>_bucket_delitem</i>. Além do mecanismos de iteração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChainHashMap(HashMapBase):\n",
    "    \"\"\"Hash map implemented with separate chaining for collision resolution.\"\"\"\n",
    "\n",
    "    def _bucket_getitem(self, j, k):  \n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError('Key Error: ' + repr(k))        # no match found\n",
    "        return bucket[k]                                 # may raise KeyError\n",
    "\n",
    "    def _bucket_setitem(self, j, k, v):\n",
    "        if self._table[j] is None:\n",
    "            self._table[j] = UnsortedTableMap()     # bucket is new to the table\n",
    "        oldsize = len(self._table[j])\n",
    "        self._table[j][k] = v\n",
    "        if len(self._table[j]) > oldsize:         # key was new to the table\n",
    "            self._n += 1                            # increase overall map size\n",
    "\n",
    "    def _bucket_delitem(self, j, k):\n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError('Key Error: ' + repr(k))        # no match found\n",
    "        del bucket[k]                                    # may raise KeyError\n",
    "\n",
    "    def __iter__(self):\n",
    "        for bucket in self._table:\n",
    "            if bucket is not None:                         # a nonempty slot\n",
    "                for key in bucket:\n",
    "                    yield key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import MutableMapping\n",
    "from random import randrange         # used to pick MAD parameters\n",
    "\n",
    "class MapBase(MutableMapping):\n",
    "    \"\"\"Our own abstract base class that includes a nonpublic _Item class.\"\"\"\n",
    "\n",
    "    class _Item:\n",
    "        \"\"\"Lightweight composite to store key-value pairs as map items.\"\"\"\n",
    "        __slots__ = '_key', '_value'\n",
    "\n",
    "        def __init__(self, k, v):\n",
    "            self._key = k\n",
    "            self._value = v\n",
    "\n",
    "    def __eq__(self, other):               \n",
    "        return self._key == other._key   # compare items based on their keys\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not (self == other)       # opposite of __eq__\n",
    "\n",
    "    def __lt__(self, other):               \n",
    "        return self._key < other._key    # compare items based on their keys\n",
    "\n",
    "\n",
    "class UnsortedTableMap(MapBase):\n",
    "    \"\"\"Map implementation using an unordered list.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Create an empty map.\"\"\"\n",
    "        self._table = []                              # list of _Item's\n",
    "  \n",
    "    def __getitem__(self, k):\n",
    "        \"\"\"Return value associated with key k (raise KeyError if not found).\"\"\"\n",
    "        for item in self._table:\n",
    "            if k == item._key:\n",
    "                return item._value\n",
    "        raise KeyError('Key Error: ' + repr(k))\n",
    "\n",
    "    def __setitem__(self, k, v):\n",
    "        \"\"\"Assign value v to key k, overwriting existing value if present.\"\"\"\n",
    "        for item in self._table:\n",
    "            if k == item._key:                          # Found a match:\n",
    "                item._value = v                           # reassign value\n",
    "                return                                    # and quit    \n",
    "        # did not find match for key\n",
    "        self._table.append(self._Item(k,v))\n",
    "\n",
    "    def __delitem__(self, k):\n",
    "        \"\"\"Remove item associated with key k (raise KeyError if not found).\"\"\"\n",
    "        for j in range(len(self._table)):\n",
    "            if k == self._table[j]._key:                # Found a match:\n",
    "                self._table.pop(j)                        # remove item\n",
    "                return                                    # and quit    \n",
    "        raise KeyError('Key Error: ' + repr(k))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return number of items in the map.\"\"\"\n",
    "        return len(self._table)\n",
    "\n",
    "    def __iter__(self):                             \n",
    "        \"\"\"Generate iteration of the map's keys.\"\"\"\n",
    "        for item in self._table:\n",
    "            yield item._key                             # yield the KEY\n",
    "\n",
    "\n",
    "class HashMapBase(MapBase):\n",
    "    \"\"\"Abstract base class for map using hash-table with MAD compression.\n",
    "    Keys must be hashable and non-None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cap=11, p=109345121):\n",
    "        \"\"\"Create an empty hash-table map.\n",
    "        cap     initial table size (default 11)\n",
    "        p       positive prime used for MAD (default 109345121)\n",
    "        \"\"\"\n",
    "        self._table = cap * [None]\n",
    "        self._n = 0                                   # number of entries in the map\n",
    "        self._prime = p                               # prime for MAD compression\n",
    "        self._scale = 1 + randrange(p-1)              # scale from 1 to p-1 for MAD\n",
    "        self._shift = randrange(p)                    # shift from 0 to p-1 for MAD\n",
    "\n",
    "    def _hash_function(self, k):\n",
    "        return (hash(k)*self._scale + self._shift) % self._prime % len(self._table)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._n\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        j = self._hash_function(k)\n",
    "        return self._bucket_getitem(j, k)             # may raise KeyError\n",
    "\n",
    "    def __setitem__(self, k, v):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_setitem(j, k, v)                 # subroutine maintains self._n\n",
    "        if self._n > len(self._table) // 2:           # keep load factor <= 0.5\n",
    "            self._resize(2 * len(self._table) - 1)      # number 2^x - 1 is often prime\n",
    "\n",
    "    def __delitem__(self, k):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_delitem(j, k)                    # may raise KeyError\n",
    "        self._n -= 1\n",
    "\n",
    "    def _resize(self, c):\n",
    "        \"\"\"Resize bucket array to capacity c and rehash all items.\"\"\"\n",
    "        old = list(self.items())       # use iteration to record existing items\n",
    "        self._table = c * [None]       # then reset table to desired capacity\n",
    "        self._n = 0                    # n recomputed during subsequent adds\n",
    "        for (k,v) in old:\n",
    "            self[k] = v                  # reinsert old key-value pair\n",
    "\n",
    "\n",
    "class ChainHashMap(HashMapBase):\n",
    "    \"\"\"Hash map implemented with separate chaining for collision resolution.\"\"\"\n",
    "\n",
    "    def _bucket_getitem(self, j, k):  \n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError('Key Error: ' + repr(k))        # no match found\n",
    "        return bucket[k]                                 # may raise KeyError\n",
    "\n",
    "    def _bucket_setitem(self, j, k, v):\n",
    "        if self._table[j] is None:\n",
    "            self._table[j] = UnsortedTableMap()     # bucket is new to the table\n",
    "        oldsize = len(self._table[j])\n",
    "        self._table[j][k] = v\n",
    "        if len(self._table[j]) > oldsize:         # key was new to the table\n",
    "            self._n += 1                            # increase overall map size\n",
    "\n",
    "    def _bucket_delitem(self, j, k):\n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError('Key Error: ' + repr(k))        # no match found\n",
    "        del bucket[k]                                    # may raise KeyError\n",
    "\n",
    "    def __iter__(self):\n",
    "        for bucket in self._table:\n",
    "            if bucket is not None:                         # a nonempty slot\n",
    "                for key in bucket:\n",
    "                    yield key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação: O problema da soma de pares\n",
    "\n",
    "O problema  da soma de pares, pode ser apresentado da seguinte forma. Dado um inteiro $k$ e uma lista $A$ de valores desordenados, encontre um par $\\{x, y\\} \\subset A$ tal que $x + y = k$. Trata-se de um caso particular do problema de soma de subconjuntos (<i>subset sum problem</i>), que é NP-difícil. \n",
    "\n",
    "Uma abordagem inicial consiste em checar todos os pares explicitamente. Como é necessário percorrer todos os pares de elementos e há $\\frac{n^2 - n}{2}$ pares, então o algoritmo é $O(n^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.18 s, sys: 0 ns, total: 1.18 s\n",
      "Wall time: 1.18 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, 104)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import seed, randint\n",
    "\n",
    "def pair_sum1(k, A):\n",
    "    for i, x in enumerate(A):\n",
    "        for y in A[i:]:\n",
    "            if x + y == k:\n",
    "                return x, y\n",
    "            \n",
    "            \n",
    "seed(0)\n",
    "lb, ub = 0, 100000\n",
    "max_nums = 100000\n",
    "A = [randint(lb, ub) for _ in range(max_nums)]\n",
    "k = 113         \n",
    "%time pair_sum1(k, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma segunda opção consiste em, para cada $x$ buscar por $y=k-x$ no vetor. Dessa forma, a busca por $k-x$ pode ser feita percorrendo o vetor, embora isso também resulte em um algoritmo $O(n^2)$. No entanto, pode-se primeiramente ordenar o vetor $A$, permitindo a utilização de busca binária por $y=k-x$. Dessa forma, tem-se um algoritmo $O(nlogn)$.\n",
    "\n",
    "Uma terceira opção (<i>pair\\_sum2</i>, a seguir) consiste em utilizar uma tabela <i>hash</i> com $x$ sendo a chave e $y = k-x$ seu respectivo valor. Considere uma implementação utilizando <i>separate chaining</i>. Dessa forma, para cada $x \\in A$, é necessário buscar por $y = k-x$ apenas no <i>bucket</i> identificado por $h(x)$. Tal <i>bucket</i> possui tamanho médio $\\frac{n}{cap}$, em que $cap$ é o tamanho da lista de <i>buckets</i>. Se a capacidade $cap$ for $O(n)$, então a busca possui complexidade esperada $O(1)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 104)\n",
      "CPU times: user 1.16 s, sys: 0 ns, total: 1.16 s\n",
      "Wall time: 1.16 s\n",
      "(54, 59)\n",
      "CPU times: user 54.5 ms, sys: 0 ns, total: 54.5 ms\n",
      "Wall time: 54.3 ms\n"
     ]
    }
   ],
   "source": [
    "from random import seed, randint\n",
    "from collections import MutableMapping\n",
    "from random import randrange         # used to pick MAD parameters\n",
    "\n",
    "class MapBase(MutableMapping):\n",
    "    \"\"\"Our own abstract base class that includes a nonpublic _Item class.\"\"\"\n",
    "\n",
    "  #------------------------------- nested _Item class -------------------------------\n",
    "    class _Item:\n",
    "        \"\"\"Lightweight composite to store key-value pairs as map items.\"\"\"\n",
    "        __slots__ = '_key', '_value'\n",
    "\n",
    "        def __init__(self, k, v):\n",
    "            self._key = k\n",
    "            self._value = v\n",
    "\n",
    "    def __eq__(self, other):               \n",
    "        return self._key == other._key   # compare items based on their keys\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not (self == other)       # opposite of __eq__\n",
    "\n",
    "    def __lt__(self, other):               \n",
    "        return self._key < other._key    # compare items based on their keys\n",
    "\n",
    "\n",
    "class UnsortedTableMap(MapBase):\n",
    "    \"\"\"Map implementation using an unordered list.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Create an empty map.\"\"\"\n",
    "        self._table = []                              # list of _Item's\n",
    "  \n",
    "    def __getitem__(self, k):\n",
    "        \"\"\"Return value associated with key k (raise KeyError if not found).\"\"\"\n",
    "        for item in self._table:\n",
    "            if k == item._key:\n",
    "                return item._value\n",
    "        raise KeyError('Key Error: ' + repr(k))\n",
    "\n",
    "    def __setitem__(self, k, v):\n",
    "        \"\"\"Assign value v to key k, overwriting existing value if present.\"\"\"\n",
    "        for item in self._table:\n",
    "            if k == item._key:                          # Found a match:\n",
    "                item._value = v                           # reassign value\n",
    "                return                                    # and quit    \n",
    "        # did not find match for key\n",
    "        self._table.append(self._Item(k,v))\n",
    "\n",
    "    def __delitem__(self, k):\n",
    "        \"\"\"Remove item associated with key k (raise KeyError if not found).\"\"\"\n",
    "        for j in range(len(self._table)):\n",
    "            if k == self._table[j]._key:                # Found a match:\n",
    "                self._table.pop(j)                        # remove item\n",
    "                return                                    # and quit    \n",
    "        raise KeyError('Key Error: ' + repr(k))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return number of items in the map.\"\"\"\n",
    "        return len(self._table)\n",
    "\n",
    "    def __iter__(self):                             \n",
    "        \"\"\"Generate iteration of the map's keys.\"\"\"\n",
    "        for item in self._table:\n",
    "            yield item._key                             # yield the KEY\n",
    "\n",
    "\n",
    "class HashMapBase(MapBase):\n",
    "    \"\"\"Abstract base class for map using hash-table with MAD compression.\n",
    "    Keys must be hashable and non-None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cap=11, p=109345121):\n",
    "        \"\"\"Create an empty hash-table map.\n",
    "        cap     initial table size (default 11)\n",
    "        p       positive prime used for MAD (default 109345121)\n",
    "        \"\"\"\n",
    "        self._table = cap * [None]\n",
    "        self._n = 0                                   # number of entries in the map\n",
    "        self._prime = p                               # prime for MAD compression\n",
    "        self._scale = 1 + randrange(p-1)              # scale from 1 to p-1 for MAD\n",
    "        self._shift = randrange(p)                    # shift from 0 to p-1 for MAD\n",
    "\n",
    "    def _hash_function(self, k):\n",
    "        return (hash(k)*self._scale + self._shift) % self._prime % len(self._table)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._n\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        j = self._hash_function(k)\n",
    "        return self._bucket_getitem(j, k)             # may raise KeyError\n",
    "\n",
    "    def __setitem__(self, k, v):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_setitem(j, k, v)                 # subroutine maintains self._n\n",
    "        if self._n > len(self._table) // 2:           # keep load factor <= 0.5\n",
    "            self._resize(2 * len(self._table) - 1)      # number 2^x - 1 is often prime\n",
    "\n",
    "    def __delitem__(self, k):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_delitem(j, k)                    # may raise KeyError\n",
    "        self._n -= 1\n",
    "\n",
    "    def _resize(self, c):\n",
    "        \"\"\"Resize bucket array to capacity c and rehash all items.\"\"\"\n",
    "        old = list(self.items())       # use iteration to record existing items\n",
    "        self._table = c * [None]       # then reset table to desired capacity\n",
    "        self._n = 0                    # n recomputed during subsequent adds\n",
    "        for (k,v) in old:\n",
    "            self[k] = v                  # reinsert old key-value pair\n",
    "\n",
    "\n",
    "class ChainHashMap(HashMapBase):\n",
    "    \"\"\"Hash map implemented with separate chaining for collision resolution.\"\"\"\n",
    "\n",
    "    def _bucket_getitem(self, j, k):  \n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError('Key Error: ' + repr(k))        # no match found\n",
    "        return bucket[k]                                 # may raise KeyError\n",
    "\n",
    "    def _bucket_setitem(self, j, k, v):\n",
    "        if self._table[j] is None:\n",
    "            self._table[j] = UnsortedTableMap()     # bucket is new to the table\n",
    "        oldsize = len(self._table[j])\n",
    "        self._table[j][k] = v\n",
    "        if len(self._table[j]) > oldsize:         # key was new to the table\n",
    "            self._n += 1                            # increase overall map size\n",
    "\n",
    "    def _bucket_delitem(self, j, k):\n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError('Key Error: ' + repr(k))        # no match found\n",
    "        del bucket[k]                                    # may raise KeyError\n",
    "\n",
    "    def __iter__(self):\n",
    "        for bucket in self._table:\n",
    "            if bucket is not None:                         # a nonempty slot\n",
    "                for key in bucket:\n",
    "                    yield key\n",
    "   \n",
    "        \n",
    "def pair_sum2(k, A):    \n",
    "    hash_table = ChainHashMap(cap=10)\n",
    "    for x in A:\n",
    "        y = k - x\n",
    "        if y in hash_table:\n",
    "            return x, y\n",
    "        else:\n",
    "            hash_table[x] = y\n",
    "\n",
    "seed(0)\n",
    "lb, ub = 0, 100000\n",
    "max_nums = 100000\n",
    "A = [randint(lb, ub) for _ in range(max_nums)]\n",
    "k = 113         \n",
    "%time print(pair_sum1(k, A))\n",
    "%time print(pair_sum2(k, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercícios\n",
    "1. Discuta a importância de códigos <i>hash</i> de um objeto serem imutáveis. Pense na inserção e na futura busca do objeto em uma tabela <i>hash</i>\n",
    "2. Considere o problema da soma de pares, implemente a versão que ordena o vetor $A$ e, então, utiliza busca binária para encontrar $y$. Através de um exemplo, compare a sua eficiência com as outras versões apresentadas.\n",
    "3. O recorte de código a seguir é relacionado à implementação da classe <i>ProbeHashMap</i> que implementa a estratégia de sondagem linear para gerenciar as colisões. Complete o código adequadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbeHashMap(HashMapBase):\n",
    "    \"\"\"Hash map implemented with linear probing for collision resolution.\"\"\"\n",
    "    _AVAIL = object()       # sentinal marks locations of previous deletions\n",
    "\n",
    "    def _is_available(self, j):\n",
    "        \"\"\"Return True if index j is available in table.\"\"\"\n",
    "        pass\n",
    "        \n",
    "\n",
    "    def _find_slot(self, j, k):\n",
    "        \"\"\"Search for key k in bucket at index j.\n",
    "        Return (success, index) tuple, described as follows:\n",
    "        If match was found, success is True and index denotes its location.\n",
    "        If no match found, success is False and index denotes first available slot.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def _bucket_getitem(self, j, k):\n",
    "        #...\n",
    "        if not found:\n",
    "            raise KeyError('Key Error: ' + repr(k))        # no match found\n",
    "        #...\n",
    "\n",
    "    def _bucket_setitem(self, j, k, v):\n",
    "        pass\n",
    "\n",
    "    def _bucket_delitem(self, j, k):\n",
    "        #...\n",
    "        if not found:\n",
    "            raise KeyError('Key Error: ' + repr(k))        # no match found\n",
    "        self._table[s] = ProbeHashMap._AVAIL             # mark as vacated\n",
    "        #...\n",
    "\n",
    "    def __iter__(self):\n",
    "        for j in range(len(self._table)):                # scan entire table\n",
    "            if not self._is_available(j):\n",
    "                yield self._table[j]._key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Referências\n",
    "\n",
    "- Material do Prof. Dr. Mário Felice. http://www2.dc.ufscar.br/~mario/ensino/2019s2/aed1/aed1.php\n",
    "- Goodrich, Michael T., Roberto Tamassia, and Michael H. Goldwasser. Data structures and algorithms in Python. John Wiley & Sons Ltd, 2013.\n",
    "- Bento, Lucila Maria de Souza, Vinícius Gusmão Pereira de Sá, and Jayme Luiz Szwarcfiter. \"Some Illustrative Examples on the Use of Hash Tables.\" Pesquisa Operacional 35.2 (2015): 423-437."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
